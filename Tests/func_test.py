#!/usr/bin/python
import cv2
import numpy as np
np.seterr(divide='ignore', invalid='ignore')
np.set_printoptions(threshold=np.inf)
import scipy
import cPickle as pickle
import time
import sys
sys.path.append('../py')
sys.path.append('../py/Piotr_Ozimek_retina')
import retina_cuda
import cortex_cuda
import retina
import cortex

retina_path = '../Retinas'
mat_data = '../Retinas'
coeff = [0,0,0,0]
loc = [0,0,0,0]

coeff[0] = scipy.io.loadmat(mat_data+'/coefficients.mat')['M']
coeff[1] = scipy.io.loadmat(mat_data+'/coeff4k.mat')['M4k']
coeff[2] = scipy.io.loadmat(mat_data+'/coeff1k.mat')['M1k']
coeff[3] = scipy.io.loadmat(retina_path+'/coeffv2_1.mat')['coeffv2']
loc[0] = scipy.io.loadmat(mat_data+'/locations.mat')['ind']
loc[1] = scipy.io.loadmat(mat_data+'/loc4k.mat')['ind4k']
loc[2] = scipy.io.loadmat(mat_data+'/loc1k.mat')['ind1k']
loc[3] = scipy.io.loadmat(retina_path+'/locv2_1.mat')['locv2']
ret50k = scipy.io.loadmat(retina_path+'/ret50k_sorted.mat')
with open(retina_path + '/ret50k_loc.pkl', 'rb') as handle:
    loc50k = pickle.load(handle)
with open(retina_path + '/ret50k_coeff.pkl', 'rb') as handle:
    coeff50k = pickle.load(handle)

def create_retina(loc, coeff, img_size, center, gauss_norm=None):
    # Instantiate retina
    ret = retina_cuda.Retina()
    # Set retina's parameters
    # It is good practice to initialise the retina once
    # and use for multiple sampling and inversion without changin the parameters
    ret.set_samplingfields(loc, coeff) # setting a different samplingfield does not affect the other parameters
    # Changing the parameters below will lead to an invalid gauss norm image (must be reassigned again / generate)
    ret.image_height = img_size[0]

    ret.image_width = img_size[1]
    ret.rgb = (len(img_size) == 3)
    ret.center_x = center[0]
    ret.center_y = center[1]
    # Once image parameters are known,CUDA can generate the gauss norm image (leave the parameter empty or None)
    # or assign a pregenerated one (will check the size)
    ret.set_gauss_norm(gauss_norm)
    # Retina is ready to use
    return ret

def create_cortex_from_fields(loc, alpha=15, shrink=0.5, k_width=7, sigma=0.8, gauss100=None, rgb=False):
    # Instantiate cortex
    cort = cortex_cuda.Cortex()
    # Set parameters. Alpha and shrink should be set before anything else
    # Changing these parameters will invalidate the L_loc and R_loc
    cort.rgb = rgb
    cort.alpha = alpha
    cort.shrink = shrink
    # gauss100 can be generated by cortex_cuda by leaving gauss100=None
    # and provide kernel width and sigma
    # or can be assigned (as in retina): k_width still mandatory
    cort.set_gauss100(k_width, sigma, gauss100)
    # locations and cort img size can be generated by CUDA,
    # from the samplingfields' locations
    cort.init_from_sampling_fields(loc)
    return cort

def create_cortex_from_fields_and_locs(L, R, L_loc, R_loc, k_width=7, sigma=0.8, gauss100=None, rgb=False):
    # Instantiate cortex
    cort = cortex_cuda.Cortex()
    cort.rgb = rgb
    #If the user provides L_loc and R_loc there is no need to set alpha and shrink 
    # gauss100 can be generated by cortex_cuda by leaving gauss100=None
    # and provide kernel width and sigma
    # or can be assigned (as in retina): k_width still mandatory
    cort.set_gauss100(k_width, sigma, gauss100)
    # User can provide everything separately
    # IMPORTANT L and R must have all 7 values in a row (instead of 3) 
    # -> cortex.py line 30,32 change [i,:3] to [i,:]
    cort.set_left_sampling_fields(L)
    cort.set_right_sampling_fields(R)
    cort.set_left_cortex_locations(L_loc)
    cort.set_right_cortex_locations(R_loc)
    return cort

def evaluate(ret, cort, coeff, loc, rgb, img):
    '''
    Samples the image img with CUDA retina ret, inverse transform it with ret and 
    create the cortical image with CUDA cortex cort
    Samples and generat retina and cortical images from img with Piotrs's code
    Visually compare the results by showing the subtraction of the generatd images
    '''

    V_c = ret.sample(img) # sample with CUDA
    inv_c = ret.inverse(V_c) # inverse with CUDA
   
    l_c = cort.cort_image_left(V_c) # left cortical image CUDA
    r_c = cort.cort_image_right(V_c) # right cortical image CUDA
    c_c = np.concatenate((np.rot90(l_c),np.rot90(r_c,k=3)),axis=1) #concatenate the results into one image
 
    # create Piotr's retina and cortical images
    GI = retina.gauss_norm_img(int(img.shape[1]/2), int(img.shape[0]/2), coeff, loc, img.shape, rgb)
    L, R = cortex.LRsplit(loc)
    L_loc, R_loc = cortex.cort_map(L, R)
    L_loc, R_loc, G, cort_size = cortex.cort_prepare(L_loc, R_loc)
    V_p = retina.sample(img, img.shape[1]/2, img.shape[0]/2, coeff, loc, rgb)
    inv_p = retina.inverse(V_p, img.shape[1]/2, img.shape[0]/2, coeff, loc, GI, img.shape, rgb)
    l_p, r_p = cortex.cort_img(V_p, L, L_loc, R, R_loc, cort_size, G)
    c_p = np.concatenate((np.rot90(l_p[:-1,:]),np.rot90(r_p[:-1,:],k=3)),axis=1)

    # show CUDA results
    cv2.namedWindow("inverse CUDA", cv2.WINDOW_NORMAL)
    cv2.imshow("inverse CUDA", inv_c)
    cv2.namedWindow("cortex CUDA", cv2.WINDOW_NORMAL)
    cv2.imshow("cortex CUDA", c_c)
    
    # show Piotr's results
    cv2.namedWindow("inverse Piotr", cv2.WINDOW_NORMAL)
    cv2.imshow("inverse Piotr", inv_p)
    cv2.namedWindow("cortex Piotr", cv2.WINDOW_NORMAL)
    cv2.imshow("cortex Piotr", c_p)
    
    # show the difference of the images
    cv2.namedWindow("inverse diff", cv2.WINDOW_NORMAL)
    cv2.imshow("inverse diff", np.power((inv_c - inv_p),2) * 255)
    cv2.namedWindow("cortex diff", cv2.WINDOW_NORMAL)
    cv2.imshow("cortex diff", np.power((c_c - c_p),2) * 255)
    
def correctness_test(loc, coeff, cap, rgb=False):
    '''
    CUDA code uses the minimal initialisation from the host,
    all tracatable values are computed on the GPU
    Get an image from the camera, generate inverse and cortical image 
    with both implementation and subtract the results
    '''
    r, img = cap.read()
    if not rgb: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # create CUDA objects to pass to evaluation
    ret = create_retina(loc, coeff, img.shape, (int(img.shape[1]/2), int(img.shape[0]/2)), None)
    cort = create_cortex_from_fields(loc, rgb=rgb)

    while ord('q') != cv2.waitKey(10):
        r, img = cap.read()
        if not rgb: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        if r:
            evaluate(ret, cort, coeff, loc, rgb, img)

def compatibility_test(loc, coeff, cap, rgb=False):
    '''
    CUDA code uses different initialisations,
    passed parameters are the results of Piotr's code
    Initialise retina and cortex with external parameters
    Process camera stream
    '''
    r, img = cap.read()
    if rgb: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # CUDA
    ret = create_retina(loc, coeff, img, (img.shape[1]/2, img.shape[0]/2), None)
    V_c = ret.sample(img)
    ret.inverse(V_c)


    retina.sample(img, img.shape[1]/2, img.shape[0]/2, coeff, locs, rgb)    

if __name__ == "__main__":
    camid = -1
    cap = cv2.VideoCapture(camid)

    while not cap.isOpened():
        print 'retrying\n'
        cv2.VideoCapture(camid).release()
        cap = cv2.VideoCapture(camid)
        camid += 1

    correctness_test(loc[0], coeff[0], cap, rgb=True)
    #compatibility_test(loc[0], coeff[0], cap, False)
    
    
    quit()